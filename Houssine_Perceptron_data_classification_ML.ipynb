{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Houssine_Perceptron_data classification ML.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoussineAyedi/HoussineAyedi.github.io/blob/main/Houssine_Perceptron_data_classification_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWFn1zb8Nkew"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pki-qTsdKYLV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd # data processing\n",
        "\n",
        "# the dataset for the demo\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw4nbMyvNrSA"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sirqY2qx72bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "12eab470-f4b1-46d6-9cf6-f9d7a55419e7"
      },
      "source": [
        "# Exploring the data\n",
        "Iris = load_iris()\n",
        "Iris_df = pd.DataFrame(Iris[\"data\"])\n",
        "Iris_df[\"target\"] = pd.Series(Iris[\"target\"])\n",
        "Iris_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2    3  target\n",
              "0    5.1  3.5  1.4  0.2       0\n",
              "1    4.9  3.0  1.4  0.2       0\n",
              "2    4.7  3.2  1.3  0.2       0\n",
              "3    4.6  3.1  1.5  0.2       0\n",
              "4    5.0  3.6  1.4  0.2       0\n",
              "..   ...  ...  ...  ...     ...\n",
              "145  6.7  3.0  5.2  2.3       2\n",
              "146  6.3  2.5  5.0  1.9       2\n",
              "147  6.5  3.0  5.2  2.0       2\n",
              "148  6.2  3.4  5.4  2.3       2\n",
              "149  5.9  3.0  5.1  1.8       2\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ZNfk7f8dmA"
      },
      "source": [
        "# Creating the data\n",
        "Y = Iris_df[\"target\"]\n",
        "X = Iris_df\n",
        "X.drop(['target'], axis='columns', inplace=True)\n",
        "\n",
        "# Split into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CTehdTGKmgb"
      },
      "source": [
        "train_inputs= x_train.to_numpy()\n",
        "test_input=x_test.to_numpy()\n",
        "\n",
        "y_train=y_train.to_numpy()\n",
        "train_outputs=np.reshape(y_train ,(y_train.size,1))\n",
        "\n",
        "y_test=y_test.to_numpy()\n",
        "test_output=np.reshape(y_test ,(y_test.size,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfSxNWu0Smpv"
      },
      "source": [
        "### functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaxyImcVSoob"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def der_sigmoid(x):\n",
        "  return x*(1.0 - x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5y0OEqnOH1m"
      },
      "source": [
        "### Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cH9wKZrOLtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05cf087f-e2b1-4e08-c4ce-6c40c903d7b7"
      },
      "source": [
        "class Perceptron: \n",
        "  def __init__(self, inputs):\n",
        "    self.inputs = inputs # valeurs te3na\n",
        "    self.input_neurons =  len(train_inputs[0]) #nbr input neurons\n",
        "    self.hidden_neurons = 65 #umber of hidden neurons should be 2/3 the size of the input layer plus the size of the output layer.\n",
        "\n",
        "    self.input_weights = np.random.random((self.input_neurons, self.hidden_neurons))  # input weights \n",
        "    self.output_weights = np.random.random((self.hidden_neurons, 1))\n",
        "  \n",
        "  def predict(self, inps):\n",
        "    s1 = sigmoid(np.dot(inps, self.input_weights))\n",
        "    return sigmoid(np.dot(s1, self.output_weights))\n",
        "  \n",
        "  def train(self, t_inputs, t_outputs, epochs): #epochs hiya nafsha nbr itérations\n",
        "    for i in range(epochs):\n",
        "      s1 = sigmoid(np.dot(t_inputs, self.input_weights))\n",
        "      s2 = sigmoid(np.dot(s1, self.output_weights))\n",
        "\n",
        "      # calcul erreur et delta output layer\n",
        "      ol_error = t_outputs - s2\n",
        "      ol_delta = np.multiply(ol_error, der_sigmoid(ol_error))\n",
        "\n",
        "      # calcul erreur et delta hidden layer\n",
        "      hl_error = np.dot(ol_delta, self.output_weights.T)\n",
        "      hl_delta = np.multiply(hl_error, der_sigmoid(hl_error))\n",
        "\n",
        "      self.input_weights += np.dot(t_inputs.T, hl_delta)\n",
        "      self.output_weights += np.dot(s2.T, ol_delta)\n",
        "      \n",
        "      #last 3 losses\n",
        "      losses = []\n",
        "      losses.append(np.mean( np.abs((ol_error))))\n",
        "      # if last 3 same break print(convergence )\n",
        "\n",
        "model = Perceptron(train_inputs)\n",
        "model.predict(test_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2fVFfaPTP_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678277c8-6350-4a96-ee6f-4cb63c38ee7b"
      },
      "source": [
        "model.train(train_inputs, train_outputs, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0EtMSxxZ8wS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0577ee-c66e-4cfc-e898-b6c9c06f481b"
      },
      "source": [
        "preds = model.predict(test_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ4IjosqaGg2"
      },
      "source": [
        "preds = np.around(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXMceNsqYEqZ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l59UQvRkZ45m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5854ef-aea9-459b-8b67-857667e147dd"
      },
      "source": [
        "accuracy_score(test_output, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgkHChDRaMui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7ad87d-1b6d-429a-a9c4-68e4f0f94a9a"
      },
      "source": [
        "confusion_matrix(test_output, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  0,  0],\n",
              "       [ 9,  0,  0],\n",
              "       [ 0, 12,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYAYZRScS5f6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ9iDekeZf9a"
      },
      "source": [
        "# Compte rendu \n",
        "\n",
        "Done by **Houssine AYEDI & Rahma** SAID RT5 TP1\n",
        "and sent to \n",
        "manai.elyes@esen.tn\n"
      ]
    }
  ]
}